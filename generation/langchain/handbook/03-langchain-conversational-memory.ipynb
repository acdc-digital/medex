{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acdc-digital/medex/blob/main/generation/langchain/handbook/03-langchain-conversational-memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc93d05f",
      "metadata": {
        "id": "cc93d05f"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/langchain/handbook/03-langchain-conversational-memory.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/generation/langchain/handbook/03-langchain-conversational-memory.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hcqKO0aI6_PI",
      "metadata": {
        "id": "hcqKO0aI6_PI"
      },
      "source": [
        "#### [LangChain Handbook](https://pinecone.io/learn/langchain)\n",
        "\n",
        "# Conversational Memory\n",
        "\n",
        "Conversational memory is how chatbots can respond to our queries in a chat-like manner. It enables a coherent conversation, and without it, every query would be treated as an entirely independent input without considering past interactions.\n",
        "\n",
        "The memory allows a _\"agent\"_ to remember previous interactions with the user. By default, agents are *stateless* — meaning each incoming query is processed independently of other interactions. The only thing that exists for a stateless agent is the current input, nothing else.\n",
        "\n",
        "There are many applications where remembering previous interactions is very important, such as chatbots. Conversational memory allows us to do that.\n",
        "\n",
        "In this notebook we'll explore this form of memory in the context of the LangChain library.\n",
        "\n",
        "We'll start by importing all of the libraries that we'll be using in this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "uZR3iGJJtdDE",
      "metadata": {
        "id": "uZR3iGJJtdDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d925df59-df00-456f-b592-c0381b10baed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m759.0/759.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "66fb9c2a",
      "metadata": {
        "id": "66fb9c2a"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "\n",
        "from getpass import getpass\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import LLMChain, ConversationChain\n",
        "from langchain.chains.conversation.memory import (ConversationBufferMemory, \n",
        "                                                  ConversationSummaryMemory, \n",
        "                                                  ConversationBufferWindowMemory,\n",
        "                                                  ConversationKGMemory)\n",
        "from langchain.callbacks import get_openai_callback\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wPdWz1IdxyBR",
      "metadata": {
        "id": "wPdWz1IdxyBR"
      },
      "source": [
        "To run this notebook, we will need to use an OpenAI LLM. Here we will setup the LLM we will use for the whole notebook, just input your openai api key when prompted. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c02c4fa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c02c4fa2",
        "outputId": "fea804a1-d24f-4c6a-e80e-f7ec3c6413db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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··········\n"
          ]
        }
      ],
      "source": [
        "OPENAI_API_KEY = getpass(\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "baaa74b8",
      "metadata": {
        "id": "baaa74b8"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(\n",
        "    temperature=0, \n",
        "    openai_api_key=\"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\",\n",
        "    model_name='gpt-4'  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "309g_2pqxzzB",
      "metadata": {
        "id": "309g_2pqxzzB"
      },
      "source": [
        "Later we will make use of a `count_tokens` utility function. This will allow us to count the number of tokens we are using for each call. We define it as so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "DsC3szr6yP3L",
      "metadata": {
        "id": "DsC3szr6yP3L"
      },
      "outputs": [],
      "source": [
        "def count_tokens(chain, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = chain.run(query)\n",
        "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CnNF6i9r8RY_",
      "metadata": {
        "id": "CnNF6i9r8RY_"
      },
      "source": [
        "Now let's dive into **Conversational Memory**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1f31b4",
      "metadata": {
        "id": "6e1f31b4"
      },
      "source": [
        "## What is memory?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b919c3a",
      "metadata": {
        "id": "5b919c3a"
      },
      "source": [
        "**Definition**: Memory is an agent's capacity of remembering previous interactions with the user (think chatbots)\n",
        "\n",
        "The official definition of memory is the following:\n",
        "\n",
        "\n",
        "> By default, Chains and Agents are stateless, meaning that they treat each incoming query independently. In some applications (chatbots being a GREAT example) it is highly important to remember previous interactions, both at a short term but also at a long term level. The concept of “Memory” exists to do exactly that.\n",
        "\n",
        "\n",
        "As we will see, although this sounds really straightforward there are several different ways to implement this memory capability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3343a0e2",
      "metadata": {
        "id": "3343a0e2"
      },
      "source": [
        "Before we delve into the different memory modules that the library offers, we will introduce the chain we will be using for these examples: the `ConversationChain`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c9c13e9",
      "metadata": {
        "id": "6c9c13e9"
      },
      "source": [
        "As always, when understanding a chain it is interesting to peek into its prompt first and then take a look at its `._call` method. As we saw in the chapter on chains, we can check out the prompt by accessing the `template` within the `prompt` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "96ff1ce3",
      "metadata": {
        "id": "96ff1ce3"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "90ad394d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90ad394d",
        "outputId": "8d68809a-8c3d-4738-8890-765635303dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ],
      "source": [
        "print(conversation.prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f8b1e0c",
      "metadata": {
        "id": "9f8b1e0c"
      },
      "source": [
        "Interesting! So this chain's prompt is telling it to chat with the user and try to give truthful answers. If we look closely, there is a new component in the prompt that we didn't see when we were tinkering with the `LLMMathChain`: _history_. This is where our memory will come into play."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a7e7770",
      "metadata": {
        "id": "4a7e7770"
      },
      "source": [
        "What is this chain doing with this prompt? Let's take a look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "43bfd2da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43bfd2da",
        "outputId": "14e93727-ff3a-4fde-e7b2-fbe3fd944375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def _call(\n",
            "        self,\n",
            "        inputs: Dict[str, Any],\n",
            "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
            "    ) -> Dict[str, str]:\n",
            "        response = self.generate([inputs], run_manager=run_manager)\n",
            "        return self.create_outputs(response)[0]\n",
            "     def apply(\n",
            "        self, input_list: List[Dict[str, Any]], callbacks: Callbacks = None\n",
            "    ) -> List[Dict[str, str]]:\n",
            "        \"\"\"Utilize the LLM generate method for speed gains.\"\"\"\n",
            "        callback_manager = CallbackManager.configure(\n",
            "            callbacks, self.callbacks, self.verbose\n",
            "        )\n",
            "        run_manager = callback_manager.on_chain_start(\n",
            "            {\"name\": self.__class__.__name__},\n",
            "            {\"input_list\": input_list},\n",
            "        )\n",
            "        try:\n",
            "            response = self.generate(input_list, run_manager=run_manager)\n",
            "        except (KeyboardInterrupt, Exception) as e:\n",
            "            run_manager.on_chain_error(e)\n",
            "            raise e\n",
            "        outputs = self.create_outputs(response)\n",
            "        run_manager.on_chain_end({\"outputs\": outputs})\n",
            "        return outputs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(inspect.getsource(conversation._call), inspect.getsource(conversation.apply))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e664af",
      "metadata": {
        "id": "84e664af"
      },
      "source": [
        "Nothing really magical going on here, just a straightforward pass through an LLM. In fact, this chain inherits these methods directly from the `LLMChain` without any modification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d8f4aa79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8f4aa79",
        "outputId": "9f167d1c-6ab4-4054-9d86-1ab84f2f12a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def _call(\n",
            "        self,\n",
            "        inputs: Dict[str, Any],\n",
            "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
            "    ) -> Dict[str, str]:\n",
            "        response = self.generate([inputs], run_manager=run_manager)\n",
            "        return self.create_outputs(response)[0]\n",
            "     def apply(\n",
            "        self, input_list: List[Dict[str, Any]], callbacks: Callbacks = None\n",
            "    ) -> List[Dict[str, str]]:\n",
            "        \"\"\"Utilize the LLM generate method for speed gains.\"\"\"\n",
            "        callback_manager = CallbackManager.configure(\n",
            "            callbacks, self.callbacks, self.verbose\n",
            "        )\n",
            "        run_manager = callback_manager.on_chain_start(\n",
            "            {\"name\": self.__class__.__name__},\n",
            "            {\"input_list\": input_list},\n",
            "        )\n",
            "        try:\n",
            "            response = self.generate(input_list, run_manager=run_manager)\n",
            "        except (KeyboardInterrupt, Exception) as e:\n",
            "            run_manager.on_chain_error(e)\n",
            "            raise e\n",
            "        outputs = self.create_outputs(response)\n",
            "        run_manager.on_chain_end({\"outputs\": outputs})\n",
            "        return outputs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(inspect.getsource(LLMChain._call), inspect.getsource(LLMChain.apply))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aaa70bf",
      "metadata": {
        "id": "6aaa70bf"
      },
      "source": [
        "So basically this chain combines an input from the user with the conversation history to generate a meaningful (and hopefully truthful) response."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f5172f",
      "metadata": {
        "id": "19f5172f"
      },
      "source": [
        "Now that we've understood the basics of the chain we'll be using, we can get into memory. Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1a33f6",
      "metadata": {
        "id": "0f1a33f6"
      },
      "source": [
        "## Memory types"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d732b7a",
      "metadata": {
        "id": "4d732b7a"
      },
      "source": [
        "In this section we will review several memory types and analyze the pros and cons of each one, so you can choose the best one for your use case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d70642",
      "metadata": {
        "id": "04d70642"
      },
      "source": [
        "### Memory type #1: ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d3cb2b",
      "metadata": {
        "id": "53d3cb2b"
      },
      "source": [
        "The `ConversationBufferMemory` does just what its name suggests: it keeps a buffer of the previous conversation excerpts as part of the context in the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80a974a",
      "metadata": {
        "id": "d80a974a"
      },
      "source": [
        "**Key feature:** _the conversation buffer memory keeps the previous pieces of conversation completely unmodified, in their raw form._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2267f1f0",
      "metadata": {
        "id": "2267f1f0"
      },
      "outputs": [],
      "source": [
        "conversation_buf = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lseziAMcAyvX",
      "metadata": {
        "id": "lseziAMcAyvX"
      },
      "source": [
        "We pass a user prompt the the `ConversationBufferMemory` like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "M0cwooC5A5Id",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0cwooC5A5Id",
        "outputId": "93fc9c10-6b97-4712-dea0-1f0182b4eba4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Good morning AI!',\n",
              " 'history': '',\n",
              " 'response': \"Good morning! I hope you're having a great day so far. What can I help you with today?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "conversation_buf(\"Good morning AI!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xlKINTFYA9eo",
      "metadata": {
        "id": "xlKINTFYA9eo"
      },
      "source": [
        "This one call used a total of `85` tokens, but we can't see that from the above. If we'd like to count the number of tokens being used we just pass our conversation chain object and the message we'd like to input via the `count_tokens` function we defined earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d1bd5a88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "d1bd5a88",
        "outputId": "0db70a50-6441-4401-a11b-a96e3d3a23a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 508 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's a fascinating topic! Integrating Large Language Models (LLMs) with external knowledge can significantly enhance their capabilities and improve their performance in various tasks. There are several ways to achieve this integration:\\n\\n1. Pre-training with external knowledge: You can incorporate external knowledge during the pre-training phase of the LLM. This can be done by adding relevant data from knowledge bases, structured databases, or other sources to the training corpus. This way, the model learns to understand and use this external knowledge during its training.\\n\\n2. Fine-tuning with external knowledge: After pre-training, you can fine-tune the LLM on a specific task using a dataset that includes external knowledge. This helps the model to better understand the task and the context in which the external knowledge is relevant.\\n\\n3. Knowledge-augmented models: You can design models that explicitly incorporate external knowledge during the inference process. This can be done by adding a knowledge retrieval component to the model, which can query external knowledge bases or databases to retrieve relevant information. The retrieved information can then be used to guide the model's predictions or responses.\\n\\n4. Hybrid models: Another approach is to combine LLMs with other types of models, such as knowledge graph embeddings or rule-based systems, to leverage the strengths of both approaches. This can help improve the model's performance in tasks that require reasoning or understanding complex relationships between entities.\\n\\n5. Prompt engineering: You can also use carefully designed prompts to encourage the LLM to access and use external knowledge during inference. This can be done by providing context or asking questions that require the model to use specific pieces of information from external sources.\\n\\nIntegrating LLMs with external knowledge has the potential to greatly improve their performance in various tasks, such as question-answering, summarization, and recommendation systems. It can also help address some of the limitations of current LLMs, such as their reliance on the training data and their inability to reason about complex relationships between entities.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_buf, \n",
        "    \"My interest here is to explore the potential of integrating Large Language Models with external knowledge\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "146170ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "146170ca",
        "outputId": "aa25f798-d3c3-4083-9595-6887a167375d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1000 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Certainly! Here are some possibilities for integrating LLMs with external knowledge, along with potential applications and benefits:\\n\\n1. Domain-specific LLMs: By incorporating external knowledge from specific domains (e.g., medicine, law, finance), you can create LLMs that are better suited for tasks within those domains. This can lead to improved performance in domain-specific question-answering, document summarization, and information extraction tasks.\\n\\n2. Multilingual LLMs: Integrating external knowledge from multiple languages can help create multilingual LLMs that can understand and generate text in various languages. This can be useful for tasks like machine translation, cross-lingual information retrieval, and multilingual sentiment analysis.\\n\\n3. Commonsense reasoning: Incorporating external knowledge about commonsense facts and relationships can help LLMs better understand and reason about everyday situations. This can improve their performance in tasks like story generation, dialogue systems, and predicting the outcomes of events.\\n\\n4. Fact-checking and verification: By integrating external knowledge sources, LLMs can be used for fact-checking and verifying the accuracy of statements or claims. This can be useful in applications like news verification, rumor detection, and combating misinformation.\\n\\n5. Personalized recommendations: LLMs can be integrated with user-specific knowledge, such as preferences, interests, and browsing history, to provide personalized recommendations for content, products, or services.\\n\\n6. Explainable AI: Integrating LLMs with external knowledge can help generate more interpretable and explainable predictions or recommendations. This can be useful in applications where understanding the reasoning behind a model's output is important, such as medical diagnosis or financial decision-making.\\n\\n7. Interactive learning: LLMs can be integrated with external knowledge to enable interactive learning, where the model can ask questions or request additional information from users or other sources to improve its understanding of a task or problem.\\n\\n8. Collaborative AI systems: Integrating LLMs with external knowledge can enable the development of collaborative AI systems that can work together with humans or other AI agents to solve complex problems, such as scientific research, engineering design, or policy-making.\\n\\nThese are just a few possibilities for integrating LLMs with external knowledge. The potential applications and benefits are vast, and exploring these possibilities can lead to significant advancements in AI and its impact on various industries and domains.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_buf,\n",
        "    \"I just want to analyze the different possibilities. What can you think of?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3e15411a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "3e15411a",
        "outputId": "eddf721f-070e-4f85-e8f8-2d4851ef4c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1556 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There are several types of data sources that can be used to provide context to an LLM. Some of these include:\\n\\n1. Structured data sources: These include databases, knowledge graphs, and ontologies that store information in a structured format. Examples include DBpedia, Wikidata, and Freebase. Structured data sources can be used to provide factual information, relationships between entities, and hierarchical information.\\n\\n2. Semi-structured data sources: These are data sources that have some structure but are not as rigidly organized as structured data sources. Examples include Wikipedia, which contains infoboxes with structured information, and web tables that can be found on various websites. These sources can provide a mix of factual information and descriptive text.\\n\\n3. Unstructured data sources: These include sources like news articles, research papers, books, and web pages that contain information in a free-text format. While it may be more challenging to extract specific pieces of information from unstructured data, these sources can provide rich context and background information on a wide range of topics.\\n\\n4. Domain-specific data sources: These are data sources that focus on specific domains or industries, such as medical databases (e.g., PubMed), legal databases (e.g., LexisNexis), or financial databases (e.g., Bloomberg). These sources can provide specialized knowledge and context relevant to specific tasks or applications.\\n\\n5. Multilingual data sources: These are data sources that contain information in multiple languages, such as parallel corpora for machine translation or multilingual knowledge bases. Integrating multilingual data sources can help provide context for tasks that involve multiple languages or require cross-lingual understanding.\\n\\n6. Social media data: Social media platforms like Twitter, Facebook, and Reddit contain a wealth of user-generated content that can provide context on current events, trends, and public opinions. This data can be useful for tasks like sentiment analysis, event detection, and trend analysis.\\n\\n7. User-specific data: This includes data that is specific to individual users, such as their browsing history, preferences, or interactions with a system. This type of data can be used to provide personalized context and recommendations.\\n\\n8. Sensor data: In some cases, context can be provided by sensor data, such as GPS coordinates, temperature readings, or images from cameras. This type of data can be useful for tasks that involve understanding the physical world or making predictions based on real-time data.\\n\\nThese are just a few examples of the types of data sources that can be used to provide context to an LLM. The choice of data source(s) will depend on the specific task or application and the type of context that is needed to improve the model's performance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_buf, \n",
        "    \"Which data source types could be used to give context to the model?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3352cc48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "3352cc48",
        "outputId": "769313d6-ce71-4f51-d87b-5323be957923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1629 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Your aim is to explore the potential of integrating Large Language Models (LLMs) with external knowledge. You're interested in analyzing different possibilities for this integration, understanding the types of data sources that can be used to provide context to the model, and discussing potential applications and benefits of integrating LLMs with external knowledge.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_buf, \n",
        "    \"What is my aim again?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "431b74ff",
      "metadata": {
        "id": "431b74ff"
      },
      "source": [
        "Our LLM with `ConversationBufferMemory` can clearly remember earlier interactions in the conversation. Let's take a closer look to how the LLM is saving our previous conversation. We can do this by accessing the `.buffer` attribute for the `.memory` in our chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "984afd09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "984afd09",
        "outputId": "d3739338-1f08-4809-a494-6d81a8e7f5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Good morning AI!\n",
            "AI: Good morning! I hope you're having a great day so far. What can I help you with today?\n",
            "Human: My interest here is to explore the potential of integrating Large Language Models with external knowledge\n",
            "AI: That's a fascinating topic! Integrating Large Language Models (LLMs) with external knowledge can significantly enhance their capabilities and improve their performance in various tasks. There are several ways to achieve this integration:\n",
            "\n",
            "1. Pre-training with external knowledge: You can incorporate external knowledge during the pre-training phase of the LLM. This can be done by adding relevant data from knowledge bases, structured databases, or other sources to the training corpus. This way, the model learns to understand and use this external knowledge during its training.\n",
            "\n",
            "2. Fine-tuning with external knowledge: After pre-training, you can fine-tune the LLM on a specific task using a dataset that includes external knowledge. This helps the model to better understand the task and the context in which the external knowledge is relevant.\n",
            "\n",
            "3. Knowledge-augmented models: You can design models that explicitly incorporate external knowledge during the inference process. This can be done by adding a knowledge retrieval component to the model, which can query external knowledge bases or databases to retrieve relevant information. The retrieved information can then be used to guide the model's predictions or responses.\n",
            "\n",
            "4. Hybrid models: Another approach is to combine LLMs with other types of models, such as knowledge graph embeddings or rule-based systems, to leverage the strengths of both approaches. This can help improve the model's performance in tasks that require reasoning or understanding complex relationships between entities.\n",
            "\n",
            "5. Prompt engineering: You can also use carefully designed prompts to encourage the LLM to access and use external knowledge during inference. This can be done by providing context or asking questions that require the model to use specific pieces of information from external sources.\n",
            "\n",
            "Integrating LLMs with external knowledge has the potential to greatly improve their performance in various tasks, such as question-answering, summarization, and recommendation systems. It can also help address some of the limitations of current LLMs, such as their reliance on the training data and their inability to reason about complex relationships between entities.\n",
            "Human: I just want to analyze the different possibilities. What can you think of?\n",
            "AI: Certainly! Here are some possibilities for integrating LLMs with external knowledge, along with potential applications and benefits:\n",
            "\n",
            "1. Domain-specific LLMs: By incorporating external knowledge from specific domains (e.g., medicine, law, finance), you can create LLMs that are better suited for tasks within those domains. This can lead to improved performance in domain-specific question-answering, document summarization, and information extraction tasks.\n",
            "\n",
            "2. Multilingual LLMs: Integrating external knowledge from multiple languages can help create multilingual LLMs that can understand and generate text in various languages. This can be useful for tasks like machine translation, cross-lingual information retrieval, and multilingual sentiment analysis.\n",
            "\n",
            "3. Commonsense reasoning: Incorporating external knowledge about commonsense facts and relationships can help LLMs better understand and reason about everyday situations. This can improve their performance in tasks like story generation, dialogue systems, and predicting the outcomes of events.\n",
            "\n",
            "4. Fact-checking and verification: By integrating external knowledge sources, LLMs can be used for fact-checking and verifying the accuracy of statements or claims. This can be useful in applications like news verification, rumor detection, and combating misinformation.\n",
            "\n",
            "5. Personalized recommendations: LLMs can be integrated with user-specific knowledge, such as preferences, interests, and browsing history, to provide personalized recommendations for content, products, or services.\n",
            "\n",
            "6. Explainable AI: Integrating LLMs with external knowledge can help generate more interpretable and explainable predictions or recommendations. This can be useful in applications where understanding the reasoning behind a model's output is important, such as medical diagnosis or financial decision-making.\n",
            "\n",
            "7. Interactive learning: LLMs can be integrated with external knowledge to enable interactive learning, where the model can ask questions or request additional information from users or other sources to improve its understanding of a task or problem.\n",
            "\n",
            "8. Collaborative AI systems: Integrating LLMs with external knowledge can enable the development of collaborative AI systems that can work together with humans or other AI agents to solve complex problems, such as scientific research, engineering design, or policy-making.\n",
            "\n",
            "These are just a few possibilities for integrating LLMs with external knowledge. The potential applications and benefits are vast, and exploring these possibilities can lead to significant advancements in AI and its impact on various industries and domains.\n",
            "Human: Which data source types could be used to give context to the model?\n",
            "AI: There are several types of data sources that can be used to provide context to an LLM. Some of these include:\n",
            "\n",
            "1. Structured data sources: These include databases, knowledge graphs, and ontologies that store information in a structured format. Examples include DBpedia, Wikidata, and Freebase. Structured data sources can be used to provide factual information, relationships between entities, and hierarchical information.\n",
            "\n",
            "2. Semi-structured data sources: These are data sources that have some structure but are not as rigidly organized as structured data sources. Examples include Wikipedia, which contains infoboxes with structured information, and web tables that can be found on various websites. These sources can provide a mix of factual information and descriptive text.\n",
            "\n",
            "3. Unstructured data sources: These include sources like news articles, research papers, books, and web pages that contain information in a free-text format. While it may be more challenging to extract specific pieces of information from unstructured data, these sources can provide rich context and background information on a wide range of topics.\n",
            "\n",
            "4. Domain-specific data sources: These are data sources that focus on specific domains or industries, such as medical databases (e.g., PubMed), legal databases (e.g., LexisNexis), or financial databases (e.g., Bloomberg). These sources can provide specialized knowledge and context relevant to specific tasks or applications.\n",
            "\n",
            "5. Multilingual data sources: These are data sources that contain information in multiple languages, such as parallel corpora for machine translation or multilingual knowledge bases. Integrating multilingual data sources can help provide context for tasks that involve multiple languages or require cross-lingual understanding.\n",
            "\n",
            "6. Social media data: Social media platforms like Twitter, Facebook, and Reddit contain a wealth of user-generated content that can provide context on current events, trends, and public opinions. This data can be useful for tasks like sentiment analysis, event detection, and trend analysis.\n",
            "\n",
            "7. User-specific data: This includes data that is specific to individual users, such as their browsing history, preferences, or interactions with a system. This type of data can be used to provide personalized context and recommendations.\n",
            "\n",
            "8. Sensor data: In some cases, context can be provided by sensor data, such as GPS coordinates, temperature readings, or images from cameras. This type of data can be useful for tasks that involve understanding the physical world or making predictions based on real-time data.\n",
            "\n",
            "These are just a few examples of the types of data sources that can be used to provide context to an LLM. The choice of data source(s) will depend on the specific task or application and the type of context that is needed to improve the model's performance.\n",
            "Human: What is my aim again?\n",
            "AI: Your aim is to explore the potential of integrating Large Language Models (LLMs) with external knowledge. You're interested in analyzing different possibilities for this integration, understanding the types of data sources that can be used to provide context to the model, and discussing potential applications and benefits of integrating LLMs with external knowledge.\n"
          ]
        }
      ],
      "source": [
        "print(conversation_buf.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4570267d",
      "metadata": {
        "id": "4570267d"
      },
      "source": [
        "Nice! So every piece of our conversation has been explicitly recorded and sent to the LLM in the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf1a90b",
      "metadata": {
        "id": "acf1a90b"
      },
      "source": [
        "### Memory type #2: ConversationSummaryMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f61fe9",
      "metadata": {
        "id": "01f61fe9"
      },
      "source": [
        "The problem with the `ConversationBufferMemory` is that as the conversation progresses, the token count of our context history adds up. This is problematic because we might max out our LLM with a prompt that is too large to be processed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0516c7d4",
      "metadata": {
        "id": "0516c7d4"
      },
      "source": [
        "Enter `ConversationSummaryMemory`.\n",
        "\n",
        "Again, we can infer from the name what is going on.. we will keep a summary of our previous conversation snippets as our history. How will we summarize these? LLM to the rescue."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86b0a905",
      "metadata": {
        "id": "86b0a905"
      },
      "source": [
        "**Key feature:** _the conversation summary memory keeps the previous pieces of conversation in a summarized form, where the summarization is performed by an LLM._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ea6050c",
      "metadata": {
        "id": "0ea6050c"
      },
      "source": [
        "In this case we need to send the llm to our memory constructor to power its summarization ability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f33a16a7",
      "metadata": {
        "id": "f33a16a7"
      },
      "outputs": [],
      "source": [
        "conversation_sum = ConversationChain(\n",
        "    llm=llm, \n",
        "    memory=ConversationSummaryMemory(llm=llm)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b64c4896",
      "metadata": {
        "id": "b64c4896"
      },
      "source": [
        "When we have an llm, we always have a prompt ;) Let's see what's going on inside our conversation summary memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c476824d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c476824d",
        "outputId": "685f7632-665c-489a-af65-d88e9efd87aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
            "\n",
            "EXAMPLE\n",
            "Current summary:\n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
            "\n",
            "New lines of conversation:\n",
            "Human: Why do you think artificial intelligence is a force for good?\n",
            "AI: Because artificial intelligence will help humans reach their full potential.\n",
            "\n",
            "New summary:\n",
            "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
            "END OF EXAMPLE\n",
            "\n",
            "Current summary:\n",
            "{summary}\n",
            "\n",
            "New lines of conversation:\n",
            "{new_lines}\n",
            "\n",
            "New summary:\n"
          ]
        }
      ],
      "source": [
        "print(conversation_sum.memory.prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df90cdf3",
      "metadata": {
        "id": "df90cdf3"
      },
      "source": [
        "Cool! So each new interaction is summarized and appended to a running summary as the memory of our chain. Let's see how this works in practice!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "34343665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "34343665",
        "outputId": "461a8e46-d42b-48a7-eaa0-26efb7a12fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 281 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Good morning! I hope you're having a great day so far. What can I help you with today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# without count_tokens we'd call `conversation_sum(\"Good morning AI!\")`\n",
        "# but let's keep track of our tokens:\n",
        "count_tokens(\n",
        "    conversation_sum, \n",
        "    \"Good morning AI!\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b757bba3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "b757bba3",
        "outputId": "1a83c3af-5f83-4894-b344-21befa336d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1046 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's a great topic to explore! Large Language Models, like OpenAI's GPT-3, have shown impressive capabilities in understanding and generating human-like text. However, they have some limitations when it comes to accessing external knowledge or staying up-to-date with the latest information.\\n\\nIntegrating Large Language Models with external knowledge sources can potentially improve their performance and make them more useful in various applications. There are several ways to approach this integration:\\n\\n1. Pre-training with external knowledge: You can incorporate external knowledge during the pre-training phase of the model. This can be done by adding relevant data from external sources to the training corpus, which helps the model learn more about specific domains or topics.\\n\\n2. Fine-tuning with external knowledge: After pre-training, you can fine-tune the model using a smaller dataset that contains specific information from external sources. This can help the model become more specialized in a particular domain or topic.\\n\\n3. Dynamic integration during inference: Another approach is to integrate external knowledge during the inference phase. This can be done by querying external databases or APIs to retrieve relevant information and then using that information to guide the model's response. This allows the model to access up-to-date information and provide more accurate answers.\\n\\n4. Hybrid models: You can also create hybrid models that combine the strengths of Large Language Models with other AI techniques, such as knowledge graphs or rule-based systems. This can help improve the model's ability to reason and provide more accurate and context-aware responses.\\n\\nEach of these approaches has its own set of challenges and trade-offs, but they all offer promising ways to enhance the capabilities of Large Language Models and make them more useful in real-world applications.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_sum, \n",
        "    \"My interest here is to explore the potential of integrating Large Language Models with external knowledge\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d0a373e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "d0a373e2",
        "outputId": "a6d8c699-39f0-479e-f03e-79eeb824ae96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1216 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Certainly! Here's a brief analysis of the four approaches we discussed earlier:\\n\\n1. Pre-training with external knowledge:\\n   Pros:\\n   - Incorporates external knowledge directly into the model during the initial training phase.\\n   - Can lead to better generalization and understanding of the context.\\n   Cons:\\n   - Requires a large amount of computational resources for training.\\n   - May not be suitable for rapidly changing or domain-specific knowledge.\\n\\n2. Fine-tuning with external knowledge:\\n   Pros:\\n   - Allows for the integration of domain-specific or up-to-date knowledge.\\n   - Can be more computationally efficient than pre-training with external knowledge.\\n   Cons:\\n   - May require a large labeled dataset for fine-tuning.\\n   - The model may overfit to the fine-tuning dataset, reducing its generalization capabilities.\\n\\n3. Dynamic integration during inference:\\n   Pros:\\n   - Can incorporate real-time or rapidly changing knowledge.\\n   - Does not require retraining the model, saving computational resources.\\n   Cons:\\n   - May increase the complexity of the model during inference, leading to slower response times.\\n   - The quality of the external knowledge source is crucial for the model's performance.\\n\\n4. Hybrid models:\\n   Pros:\\n   - Combines the strengths of multiple approaches, potentially leading to better performance.\\n   - Can be tailored to specific use cases or applications.\\n   Cons:\\n   - May require more complex model architectures and training procedures.\\n   - Can be challenging to balance the trade-offs between different approaches.\\n\\nEach of these approaches has its own set of advantages and challenges. The choice of which approach to use depends on factors such as the specific application, available resources, and the nature of the external knowledge to be integrated.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_sum, \n",
        "    \"I just want to analyze the different possibilities. What can you think of?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2e286f0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "2e286f0d",
        "outputId": "2f4909be-622f-4fd3-ee9d-b9385131fe32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1359 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There are various data source types that can be used to provide context to a Large Language Model. Some of these include:\\n\\n1. Structured data sources: These include databases, knowledge graphs, and ontologies that store information in a structured format. They can be used to provide factual information, relationships between entities, and hierarchical information.\\n\\n2. Semi-structured data sources: These include sources like Wikipedia, which contain a mix of structured and unstructured information. They can be used to provide general knowledge, facts, and context about various topics.\\n\\n3. Unstructured data sources: These include sources like news articles, books, and web pages that contain information in a free-text format. They can be used to provide context, opinions, and insights on various topics.\\n\\n4. Domain-specific data sources: These include sources like scientific articles, patents, and technical documents that are specific to a particular domain or industry. They can be used to provide specialized knowledge and context relevant to that domain.\\n\\n5. Social media data: This includes data from platforms like Twitter, Facebook, and Reddit, which can be used to provide insights into public opinion, trends, and real-time events.\\n\\n6. Multimedia data sources: These include sources like images, videos, and audio files that can be used to provide context through visual or auditory information.\\n\\nThe choice of data source(s) depends on the specific application, the nature of the external knowledge to be integrated, and the desired level of context and detail. It's also important to consider the quality, reliability, and accessibility of the data sources when making this decision.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_sum, \n",
        "    \"Which data source types could be used to give context to the model?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "891180f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "891180f2",
        "outputId": "ac7a2b54-c553-4b28-85fa-8b2d2493ccbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 866 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your aim is to integrate Large Language Models with external knowledge to improve their performance and usefulness in various applications. By doing so, you hope to enhance the capabilities of these models by providing them with additional context and information from diverse data sources.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_sum, \n",
        "    \"What is my aim again?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2d768e44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d768e44",
        "outputId": "585e7721-25f6-4421-d27e-0ce95caf5380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The human wants to integrate Large Language Models with external knowledge to improve their performance and usefulness in various applications. The AI explains four approaches and their pros and cons, emphasizing that the choice depends on factors such as the specific application, available resources, and the nature of the external knowledge. They discuss various data source types that can provide context to the model, with the choice depending on the application, nature of the external knowledge, and desired level of context and detail, as well as the quality, reliability, and accessibility of the data sources.\n"
          ]
        }
      ],
      "source": [
        "print(conversation_sum.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dd35c8c",
      "metadata": {
        "id": "0dd35c8c"
      },
      "source": [
        "You might be wondering.. if the aggregate token count is greater in each call here than in the buffer example, why should we use this type of memory? Well, if we check out buffer we will realize that although we are using more tokens in each instance of our conversation, our final history is shorter. This will enable us to have many more interactions before we reach our prompt's max length, making our chatbot more robust to longer conversations.\n",
        "\n",
        "We can count the number of tokens being used (without making a call to OpenAI) using the `tiktoken` tokenizer like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "nzijj4RZFX3I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzijj4RZFX3I",
        "outputId": "6d1d2059-8149-42ac-e22e-075531d6c164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buffer memory conversation length: 1570\n",
            "Summary memory conversation length: 107\n"
          ]
        }
      ],
      "source": [
        "# initialize tokenizer\n",
        "tokenizer = tiktoken.encoding_for_model('gpt-4')\n",
        "\n",
        "# show number of tokens for the memory used by each memory type\n",
        "print(\n",
        "    f'Buffer memory conversation length: {len(tokenizer.encode(conversation_buf.memory.buffer))}\\n'\n",
        "    f'Summary memory conversation length: {len(tokenizer.encode(conversation_sum.memory.buffer))}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bab0c09",
      "metadata": {
        "id": "2bab0c09"
      },
      "source": [
        "_Practical Note: the `text-davinci-003` and `gpt-3.5-turbo` models [have](https://platform.openai.com/docs/api-reference/completions/create#completions/create-max_tokens) a large max tokens count of 4096 tokens between prompt and answer._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "494830ea",
      "metadata": {
        "id": "494830ea"
      },
      "source": [
        "### Memory type #3: ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00762844",
      "metadata": {
        "id": "00762844"
      },
      "source": [
        "Another great option for these cases is the `ConversationBufferWindowMemory` where we will be keeping a few of the last interactions in our memory but we will intentionally drop the oldest ones - short-term memory if you'd like. Here the aggregate token count **and** the per-call token count will drop noticeably. We will control this window with the `k` parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "206a5915",
      "metadata": {
        "id": "206a5915"
      },
      "source": [
        "**Key feature:** _the conversation buffer window memory keeps the latest pieces of the conversation in raw form_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "45be373a",
      "metadata": {
        "id": "45be373a"
      },
      "outputs": [],
      "source": [
        "conversation_bufw = ConversationChain(\n",
        "    llm=llm, \n",
        "    memory=ConversationBufferWindowMemory(k=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fc4dd8a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fc4dd8a0",
        "outputId": "fd588818-eb92-4a75-b7ff-afcd74cbc1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 89 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Good morning! I hope you're having a great day so far. What can I help you with today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_bufw, \n",
        "    \"Good morning AI!\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b9992e8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "b9992e8d",
        "outputId": "bc039e71-7a0f-440a-fceb-47fa00513cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 487 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's a fascinating topic! Integrating Large Language Models with external knowledge can significantly enhance their capabilities and improve their performance in various tasks. There are several ways to achieve this integration:\\n\\n1. Pre-training with external knowledge: You can incorporate external knowledge during the pre-training phase of the language model. This can be done by adding relevant data from knowledge bases, structured databases, or other sources to the training corpus. This way, the model learns to understand and use this external knowledge during its training.\\n\\n2. Fine-tuning with external knowledge: After pre-training, you can fine-tune the model on a specific task using external knowledge. This can be done by creating a custom dataset that combines the task-specific data with relevant external knowledge. The model will then learn to use this knowledge to improve its performance on the task.\\n\\n3. Knowledge-augmented models: Another approach is to design models that can explicitly incorporate external knowledge during inference. This can be achieved by adding a knowledge retrieval component to the model, which can query external knowledge bases or databases to retrieve relevant information. The model can then use this information to generate more accurate and context-aware responses.\\n\\n4. Hybrid models: You can also create hybrid models that combine the strengths of both neural language models and symbolic reasoning systems. These models can leverage the powerful representation learning capabilities of neural networks and the structured reasoning capabilities of symbolic systems to better understand and use external knowledge.\\n\\n5. Dynamic knowledge integration: Some approaches focus on dynamically integrating external knowledge during the inference process. This can be done by using attention mechanisms or other techniques to selectively incorporate relevant knowledge based on the input and the current context.\\n\\nOverall, integrating Large Language Models with external knowledge has the potential to greatly improve their performance and enable them to tackle a wider range of tasks. However, it's important to carefully consider the specific requirements of each task and choose the most appropriate integration method.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_bufw, \n",
        "    \"My interest here is to explore the potential of integrating Large Language Models with external knowledge\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3f2e98d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "3f2e98d9",
        "outputId": "7f25d7c9-5e04-4c2e-e301-b96b8b6fff74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 983 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Certainly! Here are some possibilities for integrating Large Language Models with external knowledge, along with potential use cases and benefits:\\n\\n1. Question Answering Systems: By incorporating external knowledge, language models can provide more accurate and detailed answers to user queries. This can be particularly useful for domains that require specialized knowledge, such as medicine, law, or finance.\\n\\n2. Conversational AI: Integrating external knowledge can help improve the quality of responses generated by chatbots and virtual assistants. This can lead to more engaging and informative conversations, as the AI can provide context-specific information and answer questions more accurately.\\n\\n3. Information Retrieval: Language models can be enhanced with external knowledge to improve search and recommendation systems. This can help users find more relevant and high-quality content based on their queries and preferences.\\n\\n4. Knowledge Graph Construction: Language models can be used to extract and structure information from unstructured text, which can then be used to build and update knowledge graphs. Integrating external knowledge can help improve the accuracy and coverage of these knowledge graphs.\\n\\n5. Text Summarization: By incorporating external knowledge, language models can generate more informative and accurate summaries of documents. This can be particularly useful for summarizing complex or technical content, where background knowledge is essential for understanding the main points.\\n\\n6. Machine Translation: Integrating external knowledge can help improve the quality of translations generated by language models, especially for idiomatic expressions, technical terms, or culturally-specific references.\\n\\n7. Sentiment Analysis: Language models can benefit from external knowledge to better understand the sentiment and emotions expressed in text. This can help improve the accuracy of sentiment analysis systems and enable them to better capture nuances in language.\\n\\n8. Fact-checking: Language models can be used to automatically verify the accuracy of statements and claims made in text. By integrating external knowledge, these models can cross-reference information and provide more reliable fact-checking results.\\n\\n9. Creative Writing: Language models can be used to generate creative content, such as stories, poems, or scripts. Integrating external knowledge can help these models generate more coherent and contextually appropriate content.\\n\\n10. Personalized Learning: Language models can be used to create personalized learning experiences by generating content tailored to individual learners' needs and interests. Integrating external knowledge can help these models provide more accurate and relevant information, leading to more effective learning outcomes.\\n\\nThese are just a few examples of the possibilities for integrating Large Language Models with external knowledge. The specific benefits and use cases will depend on the nature of the external knowledge and the integration method used.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_bufw, \n",
        "    \"I just want to analyze the different possibilities. What can you think of?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a2a8d062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "a2a8d062",
        "outputId": "76be5c85-ab26-401d-b839-fa69955b0af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1126 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several data source types that can be used to provide context to a language model. Some of these include:\\n\\n1. Structured Data: This includes databases, spreadsheets, and other data sources with a well-defined structure. Structured data can be used to provide factual information, statistics, and other specific details to the model.\\n\\n2. Semi-structured Data: This includes data sources like XML, JSON, or HTML documents, which have some structure but may also contain unstructured content. Semi-structured data can be used to provide context in the form of metadata, tags, or other annotations.\\n\\n3. Unstructured Data: This includes text documents, articles, books, and other sources of natural language content. Unstructured data can be used to provide context in the form of background knowledge, examples, or explanations.\\n\\n4. Knowledge Graphs: These are structured representations of knowledge, consisting of entities and relationships between them. Knowledge graphs can be used to provide context in the form of facts, relationships, and hierarchies.\\n\\n5. Ontologies: These are formal representations of knowledge, typically using a controlled vocabulary and a set of relationships between terms. Ontologies can be used to provide context in the form of domain-specific concepts and relationships.\\n\\n6. APIs and Web Services: These are interfaces to external systems that can provide data or services on-demand. APIs and web services can be used to provide context in the form of real-time information, such as weather data, stock prices, or news updates.\\n\\n7. Social Media and User-Generated Content: This includes data from platforms like Twitter, Facebook, or Reddit, where users create and share content. Social media data can be used to provide context in the form of opinions, trends, or popular topics.\\n\\n8. Multimedia Content: This includes images, videos, and audio files, which can be used to provide context in the form of visual or auditory information.\\n\\n9. Domain-Specific Data Sources: These are data sources specific to a particular domain or industry, such as medical databases, legal documents, or scientific publications. Domain-specific data sources can be used to provide context in the form of specialized knowledge or terminology.\\n\\n10. Real-time Data Streams: These are data sources that provide continuous, real-time updates, such as sensor data, financial transactions, or social media feeds. Real-time data streams can be used to provide context in the form of up-to-date information or trends.\\n\\nBy integrating these different types of data sources, a language model can be provided with a rich and diverse set of contextual information, which can help improve its understanding and generation capabilities.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_bufw, \n",
        "    \"Which data source types could be used to give context to the model?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ff199a3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "ff199a3f",
        "outputId": "6c68e38a-a600-4d18-a667-2e0d0297ef3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 690 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"As a language model AI, my understanding is that your aim is to gather information about different data source types that can be used to provide context to a language model. This context can help improve the model's understanding and generation capabilities, making it more effective in generating human-like responses and providing relevant information. If you have a different aim, please let me know, and I'll be happy to help.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_bufw, \n",
        "    \"What is my aim again?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5f59f77",
      "metadata": {
        "id": "f5f59f77"
      },
      "source": [
        "As we can see, it effectively 'fogot' what we talked about in the first interaction. Let's see what it 'remembers'. Given that we set k to be `1`, we would expect it remembers only the last interaction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b354c8d",
      "metadata": {
        "id": "6b354c8d"
      },
      "source": [
        "We need to access a special method here since, in this memory type, the buffer is first passed through this method to be sent later to the llm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "85266406",
      "metadata": {
        "id": "85266406"
      },
      "outputs": [],
      "source": [
        "bufw_history = conversation_bufw.memory.load_memory_variables(\n",
        "    inputs=[]\n",
        ")['history']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5904ae2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5904ae2a",
        "outputId": "4e76b45a-6c9a-4fdf-aa6e-382c58527289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: What is my aim again?\n",
            "AI: As a language model AI, my understanding is that your aim is to gather information about different data source types that can be used to provide context to a language model. This context can help improve the model's understanding and generation capabilities, making it more effective in generating human-like responses and providing relevant information. If you have a different aim, please let me know, and I'll be happy to help.\n"
          ]
        }
      ],
      "source": [
        "print(bufw_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae8b937d",
      "metadata": {
        "id": "ae8b937d"
      },
      "source": [
        "Makes sense. \n",
        "\n",
        "On the plus side, we are shortening our conversation length when compared to buffer memory _without_ a window:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9fbb50fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fbb50fe",
        "outputId": "ad37da57-82ec-4600-a5a3-b0194b024c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buffer memory conversation length: 1570\n",
            "Summary memory conversation length: 107\n",
            "Buffer window memory conversation length: 90\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f'Buffer memory conversation length: {len(tokenizer.encode(conversation_buf.memory.buffer))}\\n'\n",
        "    f'Summary memory conversation length: {len(tokenizer.encode(conversation_sum.memory.buffer))}\\n'\n",
        "    f'Buffer window memory conversation length: {len(tokenizer.encode(bufw_history))}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69842cc1",
      "metadata": {
        "id": "69842cc1"
      },
      "source": [
        "_Practical Note: We are using `k=2` here for illustrative purposes, in most real world applications you would need a higher value for k._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aea5fc8",
      "metadata": {
        "id": "2aea5fc8"
      },
      "source": [
        "### More memory types!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daeb5162",
      "metadata": {
        "id": "daeb5162"
      },
      "source": [
        "Given that we understand memory already, we will present a few more memory types here and hopefully a brief description will be enough to understand their underlying functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0365333",
      "metadata": {
        "id": "f0365333"
      },
      "source": [
        "#### ConversationSummaryBufferMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "317f298e",
      "metadata": {
        "id": "317f298e"
      },
      "source": [
        "**Key feature:** _the conversation summary memory keeps a summary of the earliest pieces of conversation while retaining a raw recollection of the latest interactions._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57ef5c8b",
      "metadata": {
        "id": "57ef5c8b"
      },
      "source": [
        "#### ConversationKnowledgeGraphMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40248f03",
      "metadata": {
        "id": "40248f03"
      },
      "source": [
        "This is a super cool memory type that was introduced just [recently](https://twitter.com/LangChainAI/status/1625158388824043522). It is based on the concept of a _knowledge graph_ which recognizes different entities and connects them in pairs with a predicate resulting in (subject, predicate, object) triplets. This enables us to compress a lot of information into highly significant snippets that can be fed into the model as context. If you want to understand this memory type in more depth you can check out [this](https://apex974.com/articles/explore-langchain-support-for-knowledge-graph) blogpost."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91952cd1",
      "metadata": {
        "id": "91952cd1"
      },
      "source": [
        "**Key feature:** _the conversation knowledge graph memory keeps a knowledge graph of all the entities that have been mentioned in the interactions together with their semantic relationships._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "02241bc3",
      "metadata": {
        "id": "02241bc3"
      },
      "outputs": [],
      "source": [
        "# you may need to install this library\n",
        "# !pip install -qU networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c5f10a89",
      "metadata": {
        "id": "c5f10a89"
      },
      "outputs": [],
      "source": [
        "conversation_kg = ConversationChain(\n",
        "    llm=llm, \n",
        "    memory=ConversationKGMemory(llm=llm)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "65957fe2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "65957fe2",
        "outputId": "ac282e0d-c48c-4a99-f1c6-5c7326be3365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1137 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello, Human! It's nice to meet you. Mangoes are a delicious fruit, and I can understand why you like them. They're packed with vitamins and minerals, and they have a unique, sweet taste. Do you have a favorite way to enjoy mangoes, or do you just like them as they are?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "count_tokens(\n",
        "    conversation_kg, \n",
        "    \"My name is human and I like mangoes!\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74054534",
      "metadata": {
        "id": "74054534"
      },
      "source": [
        "The memory keeps a knowledge graph of everything it learned so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "5a8c54fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a8c54fb",
        "outputId": "e80c6e3b-0205-4878-a6df-6e7c952720d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Human', 'human', 'is named'), ('Human', 'mangoes', 'likes')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "conversation_kg.memory.kg.get_triples()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a1ca15",
      "metadata": {
        "id": "e1a1ca15"
      },
      "source": [
        "#### ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e9aeaf",
      "metadata": {
        "id": "41e9aeaf"
      },
      "source": [
        "**Key feature:** _the conversation entity memory keeps a recollection of the main entities that have been mentioned, together with their specific attributes._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2900a385",
      "metadata": {
        "id": "2900a385"
      },
      "source": [
        "The way this works is quite similar to the `ConversationKnowledgeGraphMemory`, you can refer to the [docs](https://langchain.readthedocs.io/en/latest/modules/memory/examples/entity_summary_memory.html) if you want to see it in action. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45112bd",
      "metadata": {
        "id": "d45112bd"
      },
      "source": [
        "## What else can we do with memory?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78296bff",
      "metadata": {
        "id": "78296bff"
      },
      "source": [
        "There are several cool things we can do with memory in langchain. We can:\n",
        "* implement our own custom memory module\n",
        "* use multiple memory modules in the same chain\n",
        "* combine agents with memory and other tools\n",
        "\n",
        "If this piques your interest, we suggest you to go take a look at the memory [how-to](https://langchain.readthedocs.io/en/latest/modules/memory/how_to_guides.html) section in the docs!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}